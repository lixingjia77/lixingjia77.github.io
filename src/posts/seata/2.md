# Seata之后：关于分布式事务讨论
> 其他代码走读还没来得及总结，也不再想让大模型来帮忙总结了（味太冲），所以拖了很久。但最近看了很多相关主题的分享和讨论，趁着东西还在脑子里先把讨论的部分总结了，走读后续再补！

**Seata**作为一种分布式事务的框架，提供了多种事务模式。其中，

- **AT模式**基于拦截sql保留操作前后镜像+全局锁写隔离+中心化的协调器实现了近似于读未提交的分布式强一致性；
- **TCC**基于2pc实现了不依赖于数据库的强一致性，但框架层本身不对隔离性做任何保证；
- **Saga模式**类似银行的冲正实现基于反向补偿的最终一致性；
- **XA模式**基于XA协议实现了中心化的事务管理机制，支持Mysql、PostgreSQL和Oracle。

但在大多数的业务中，**不会，也没必要，使用Seata**。这并不意味着分布式场景中鲜有对分布式事务尤其是一致性的需求，相反，业务需求通常都会对一致性提出或严格或放松的要求。而是在真实场景中，往往可以通过多种方式避免系统和Seata这种分布式事务中间件强耦合，并导致微服务降级为分布式单体。

## 不额外处理

当业务上没有强诉求，或者业务价值较低时，往往可以**不为分布式事务做额外处理**。

比如，我们假设有一个商家端商品管理平台的场景。创建商品接口在业务编排层服务中的现有逻辑是对商品信息作一些处理后调用商品中台的建品接口，以商品中台建品成功作为接口返回成功的唯一依据，其他任何情况返回失败。现在，我们需要增加一种活动商品类型，运营诉求是有一个活动品管理平台可以查到所有的参与活动的商家。此时，我们直接在商品中台rpc接口调用之前优先调用一个运营活动平台的接口保存商家信息即可满足活动诉求。

从理想业务视角看，商家信息与商品信息的落库确实存在**原子性的诉求**。但在实际场景中，这种诉求的"严格性"往往并不强：失败也不会造成业务故障，或者业务可以接受。因此我们可以选择不去实现严格的一致性机制。

但也需要考虑几种情况：

- 活动商家信息落库成功后，商品基本信息落库失败
- 活动商家信息落库成功后，商品基本信息落库超时
- 合法的基本商品，但非法的活动参与商家，提前返回了失败

最后一个最简单，本来就是一个活动品的建品，活动都参与不了，光给他落个普通商品也没意义，提前失败符合业务期望。

第一个也比较简单，运营品查询时多查一次中台基本信息，发现没有这个商家的关联活动品的信息，更新运营平台中商家状态即可，或者干脆不管也行。

第二个超时有两种可能，一种是落了，一种是没落。对于商家，简单的系统往往可以返回超时并引导用户以商品列表是否查得到为准。而对于运营，有时也可接受商家信息存在但参与商品为空的情况，或者查询时再查一遍中台中商品即可。

但这本身并非一个好的技术设计，只是在快速迭代的业务需求中做出权衡的一种选择。但是，从系统维护的角度，和个人技术口碑运营的角度出发。咱要真写了一个rpc和落库在一个事务里这种级别的代码，为了避免后面人看到骂你一句，建议还是在注释中说明清楚开发时的考量，并当业务发展后及时升级方案。

当业务对分布式事务提出更高的一致性诉求时，也有可以打补丁式的方案

- 基于**Binlog对账**+异常补偿/告警
- 基于天级别的**hive离线对账**

也是一种较为通用的方案。

## 本地消息表

如果业务有较为明确的一致性诉求，但业务可以接受**最终一致性**，往往可以通过**本地消息表+定时任务+下游幂等**来实现。

比如，我们考虑一个支付的场景，支付中台中通常会有一个支付网关用于对接外部支付渠道，比如超网、银联网联等等。A银行的支付网关负责发起一笔转账，但这笔转账数额非常巨大，可能需要人工审批，此时这笔支付从发起到终态需要较长的时间。支付网关对内的职责是受理这个支付并承诺将这个支付推进到终态（明确的成功或失败）。在这个场景中，支付流水实体本身既承担了记录主业务状态的职责，也充当了消息记录的角色，因此等价于我们通常所说的"**本地消息表**"。当支付网关接收到上游rpc时，一系列业务实体和本地消息表在一个数据库事务落库成功后，会立即调用三方支付接口，并通过定时任务等机制保证这个支付流水实体推进到终态。当三方支付返回明确的成功/失败后，流水状态机推进为终态，并回调上游或支持上游查询。当三方支付返回"支付已受理，是否成功待查"，定时任务用于保证周期性的触发三方的查询接口并尝试最终将流水推向终态。当超出最大时间后仍未推进为终态，则需要通知到营运，人工介入确认并推进状态即可。

当然本地消息表的基本思想没有那么复杂，更多是为了将微服务自己库的操作和rpc/mq接口放到一个事务里，所以把rpc接口的调用作为一个本地消息落自己的库并由定时任务等机制保证一定完成。而在实现层面，往往会和具体业务有着较为深度的融合，或者本地消息表的职责由一个业务实体来承担。

个人认为本地消息表有一个小前提，就是**发消息的失败不需要撤销掉本地操作**。比如一个用户活动报名写入报名表后，本地消息已记录但 MQ 发送失败，此时用户从业务视角认为"报名失败"，但报名表已有数据（幂等）。如果不清理这个状态，用户就无法再次报名，这与用户预期不符。因此这种场景需要更强的状态一致性保障，可能不适合本地消息表方案。

## 事务消息

**RocketMQ**提供了事务消息，两阶段的方式先提交半消息然后提交或者回滚。此外，业务还需要提供一个接口给rmq用于二阶段超时的时候反查是否提交或者回滚。

大多数的情况下，事务消息可以满足业务的最终一致性的需求，且对项目改造最小、性能最高。

事务消息也有一些缺点

- 相比于本地消息表，事务的中间状态对业务方不可见。
- 当服务/DB挂了，RocketMQ会大量反查请求，反而加重服务压力。
- 只保证mq发布成功，业务是否成功还得保证下游消费成功。
- （极低概率，但逻辑上存在）可能会出现本地落库成功，但RocketMQ超时导致认为回滚的问题。比如db等待锁（innodb默认50s），rmq反查多次仍然unknown认为超时，但db获取到锁后本地事务commit成功。

```java
/**
 * The minimum time of the transactional message  to be checked firstly, one message only exceed this time interval
 * that can be checked.
 */
@ImportantField
private long transactionTimeOut = 6 * 1000;

/**
 * The maximum number of times the message was checked, if exceed this value, this message will be discarded.
 */
@ImportantField
private int transactionCheckMax = 15;

/**
 * Transaction message check interval.
 */
@ImportantField
private long transactionCheckInterval = 30 * 1000;

```

默认配置：

- 最大反查次数：**transactionCheckMax = 15 次**
- 反查间隔：**transactionCheckInterval = 30 * 1000 毫秒（30秒）**
- 首次反查延迟：**transactionTimeOut = 6 * 1000 毫秒（6秒）**

6s + 30s*15 = 456s 7分多6s，其实是超过innodb默认超时时间的，大多数情况不需要担心这个，除非你的反查接口逻辑非常复杂，或者配置较为特殊。

## 去中心化的Saga

**Saga**是一个最终一致性的思想，《微服务架构设计模式》一书中花了很大的篇幅Saga。本质就是对于正向链路的每个阶段都支持反向补偿，当正向链路中某个阶段失败回滚时，前置阶段依次通过反向补偿来回滚。

这种思想有两种实现方式

- **有中心化的协调者**：比如Seata的实现，通过json之类的配置定义一个执行流程，每个正向节点可以配置补偿回滚的节点。是否回滚/提交，由中心化的协调者来控制。
- **去中心化的Saga**：不需要中心化的协调者，由各业务服务之间的约定来实现正向和补偿的流程。

支付中"**冲正**"的概念是在一笔错误的正向交易之后，通过一个完全等额的逆向交易补偿错误交易。这是一个业务诉求，但隐含了Saga的思想。

很多业务的实现往往没有特别强调Saga，但也运用的这种基于补偿的最终一致性的思想。考虑这样一种场景，用户下单后有非常多的系统都针对这个新创建的订单做了很多操作。而用户犹豫了一段时间觉得自己冲动消费了，退款了，上述操作需要依次撤销回滚。从业务上我们通常不会将这个流程称为Saga的最终一致性，而是业务的逆向链路。但这种逆向链路的实现往往也体现了Saga的思想。这种流程也通常不是中心化的协调器推动的，更多是基于**领域事件**的mq实现。

这种场景中，中心化的协调器有很大的弊端，比如：新增逻辑都需要改全局的配置、流程配置将会极度复杂、需要非常多的团队维护同一个配置。也导致巨大的风险，任何一个人改错了，对全局链路都有影响。而领域事件通过服务之间消息的订阅关系解耦了发布者和生产者，也去掉了需要显示构建的流程配置，往往是复杂系统的最佳实践，或者说唯一选择。

## 合并服务

如果你发现两个服务之间存在大量的分布式事务，还需要强一致性。那说明对**微服务划分的有问题**，建议直接合服务。

当然这里的说的微服务划分有问题不代表着早期的架构师菜，大多时候只是时代的局限性和业务发展处于不同的历史阶段导致的。随着业务的发展和复杂化，现有系统难以满足新的需求时可以考虑逐步重构以解决历史问题。

## CAP与ACID

分布式事务是**业务需求和技术架构之间平衡的艺术**。

有的项目是从出生第一天就需要考虑分布式事务的，比如银行的交易核心。有的项目是做着做着不得不引入分布式事务。对于前者，早期会有大量设计或者基于Seata实现了核心逻辑。对于后者，往往也没有必要做复杂设计支持临时或非核心链路。

分布式场景下，由于**CAP理论**，一定是难以追求完美的分布式ACID的，除非降级为分布式单体事务最终还是落在某一个单独的库上。

此外，技术架构往往取决于管理架构，当涉及到多个团队同时协调的分布式事务开发需求时，管理的复杂度也指数上升。

**Seata这种框架大一统的分布式事务中间件对于大多数业务而言都是大而无用的白象**。通过上述讨论提到的方式，通常可以满足大多业务诉求。对于分布式事务问题，我们的目标应该是在业务接受的范围内用最小的成本实现，而非实现一个极度复杂但业务价值较低的炫技方案。